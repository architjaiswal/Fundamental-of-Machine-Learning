{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Assignment 2\n",
    "\n",
    "This is an individual assignment.\n",
    "\n",
    "**Due: Tuesday, October 4 @ 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crab Dataset Description\n",
    "\n",
    "The Crab Data Set has 200 samples and 7 features (Frontal Lip, Rear Width, Length, Width, Depth, Male and Female), describing 5 morphological measurements on 50 crabs each of two color forms and both sexes, of the species *Leptograpsus* variegatus collected at Fremantle, W. Australia.\n",
    "\n",
    "* Dataset Source: Campbell, N.A. and Mahon, R.J. (1974) A multivariate study of variation in two species of rock crab of genus *Leptograpsus*. *Australian Journal of Zoology* 22, 417–425.\n",
    "\n",
    "The data set is saved in the file \"crab.txt\": the first column corresponds to the class label (crab species) and the other 7 columns correspond to the features.\n",
    "\n",
    "**Use the first 140 samples as your training set and the last 60 samples as your test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>FrontalLip</th>\n",
       "      <th>RearWidth</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>42.8</td>\n",
       "      <td>46.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>32.3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>29.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>40.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>35.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species  FrontalLip  RearWidth  Length  Width  Depth  Male  Female\n",
       "0          0        20.6       14.4    42.8   46.5   19.6     1       0\n",
       "1          1        13.3       11.1    27.8   32.3   11.3     1       0\n",
       "2          0        16.7       14.3    32.3   37.0   14.7     0       1\n",
       "3          1         9.8        8.9    20.4   23.9    8.8     0       1\n",
       "4          0        15.6       14.1    31.0   34.5   13.8     0       1\n",
       "..       ...         ...        ...     ...    ...    ...   ...     ...\n",
       "195        1        12.3       11.0    26.8   31.5   11.4     1       0\n",
       "196        1        12.0       11.1    25.4   29.2   11.0     0       1\n",
       "197        1         8.8        7.7    18.1   20.8    7.4     1       0\n",
       "198        1        16.2       15.2    34.5   40.1   13.9     0       1\n",
       "199        0        15.6       14.0    31.6   35.3   13.8     0       1\n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"crab.txt\", delimiter=\"\\t\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training data and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning the data into training and test sets\n",
    "\n",
    "x_train = data.iloc[:140,1:].to_numpy()\n",
    "t_train = data.iloc[:140,0].to_numpy()\n",
    "\n",
    "x_test = data.iloc[140:,1:].to_numpy()\n",
    "t_test = data.iloc[140:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 7), (60, 7), (140,), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, t_train.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate data for different spieces \n",
    "x_train[t_train == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for different spieces\n",
    "c0_xtrain = x_train[t_train == 0] # spiece 0\n",
    "c1_xtrain = x_train[t_train == 1] # spiece 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. Implement the Naive Bayes classifier, under the assumption that your data likelihood model $p(x|C_j)$ is a multivariate Gaussian and the prior probabilities $p(C_j)$ are dictated by the number of samples $n_j\\in\\mathbb{R}$ that you have for each class. Build your own code to implement the classifier.\n",
    "\n",
    "2. Did you encounter any problems when implementing the probabilistic generative model? What is your solution for the problem? Explain why your solution works. (Note: There is more than one solution.)\n",
    "\n",
    "3. Report your classification results in terms of a confusion matrix in both training and test set. (You can use the function [```confusion_matrix```](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) from the module ```sklearn.metrics```.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior probabilities for Class 0 and Class 1\n",
    "\n",
    "p0 = np.sum(t_train)/ x_train.shape[0]\n",
    "\n",
    "p1 = 1 - p0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling for Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('num_attribs', StandardScaler(),\n",
       "                                 [0, 1, 2, 3, 4])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This pipeline will apply Standardization to all numerical attributes \n",
    "# The attributes that are one-hot/interger-encoded (such as gender) will remain as is\n",
    "\n",
    "c0_scaling_pipeline= ColumnTransformer([('num_attribs', StandardScaler(), list(range(5)))],\n",
    "                                    remainder='passthrough')\n",
    "c0_scaling_pipeline.fit(c0_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.10555556, 13.62083333, 34.1375    , 38.10277778, 15.46527778])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of each feature column of spiece 0\n",
    "c0_scaling_pipeline.transformers_[0][1].mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_mean = c0_xtrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.1691358 ,  6.76387153, 38.45012153, 48.30138117,  8.32226659])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance for each feature column of spiece 0\n",
    "c0_scaling_pipeline.transformers_[0][1].var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covaraince for Class 0\n",
    "\n",
    "c0_cov = np.cov(c0_xtrain.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0_cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('num_attribs', StandardScaler(),\n",
       "                                 [0, 1, 2, 3, 4])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This pipeline will apply Standardization to all numerical attributes \n",
    "# The attributes that are one-hot/interger-encoded (such as gender) will remain as is\n",
    "\n",
    "c1_scaling_pipeline= ColumnTransformer([('num_attribs', StandardScaler(), list(range(5)))],\n",
    "                                    remainder='passthrough')\n",
    "c1_scaling_pipeline.fit(c1_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.03529412, 11.84705882, 30.08676471, 34.73382353, 12.56764706])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of each feature column of spiece 0\n",
    "c1_scaling_pipeline.transformers_[0][1].mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_mean = c1_xtrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.08346021,  4.50396194, 48.49261894, 63.22547362,  9.74571799])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance for each feature column of spiece 0\n",
    "c1_scaling_pipeline.transformers_[0][1].var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covaraince for Class 0\n",
    "\n",
    "c1_cov = np.cov(c1_xtrain.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# the probabaility density function (pdf) for each class\n",
    "train_y0 = multivariate_normal.pdf(x_train, mean=c0_mean, cov=c0_cov, allow_singular=True) #P(x|C0)\n",
    "train_y1 = multivariate_normal.pdf(x_train, mean=c1_mean, cov=c1_cov, allow_singular=True) #P(x|C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior distributions: they represent our classification decision\n",
    "train_pos0 = train_y0*p0 / (train_y0*p0 + train_y1*p1) # P(C0|x)\n",
    "train_pos1 = train_y1*p1 / (train_y0*p0 + train_y1*p1) # P(C1|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of spiece from the train data\n",
    "train_pre = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if train_pos1[i] > train_pos0[i]:\n",
    "        train_pre.append(1)\n",
    "    else:\n",
    "        train_pre.append(0)\n",
    "        \n",
    "train_pre = np.array(train_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data likelihoods for the test set\n",
    "\n",
    "test_y0 = multivariate_normal.pdf(x_test, mean=c0_mean, cov=c0_cov, allow_singular=True) #P(x|C0)\n",
    "test_y1 = multivariate_normal.pdf(x_test, mean=c1_mean, cov=c1_cov, allow_singular=True) #P(x|C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior Probabilities\n",
    "\n",
    "test_y0_pos = test_y0*p0 / (test_y0*p0 + test_y1*p1) #P(C0|x)\n",
    "test_y1_pos = test_y1*p1 / (test_y0*p0 + test_y1*p1) #P(C1|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of spiece from the test data\n",
    "test_pre = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    if test_y1_pos[i] > test_y0_pos[i]:\n",
    "        test_pre.append(1)\n",
    "    else:\n",
    "        test_pre.append(0)\n",
    "        \n",
    "test_pre = np.array(test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Problems Encountered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While implementing the probabilistic generative model, I encountered singular matrix error. This error means that the covariance matrix is non-invertable because its determinant is zero.\n",
    "\n",
    "The multivariate_normal.pdf() function always performs a test to verify the covariance matrix and this test can be skipped by passing allow_singular=True. \n",
    "\n",
    "However, a better solution would be to rescale the data. Professor mentioned about rescaling on the day this assignment was due, and I did not had enough time to implement it here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Classification results in terms of a confusion matrix in both training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72,  0],\n",
       "       [ 0, 68]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(t_train, train_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Alternate way of evaluating the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train - train_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0],\n",
       "       [ 0, 32]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix(t_test, test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternate way of evaluating the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test - test_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Submit Your Solution\n",
    "\n",
    "Confirm that you've successfully completed the assignment.\n",
    "\n",
    "Along with the Notebook, include a PDF of the notebook with your solutions.\n",
    "\n",
    "```add``` and ```commit``` the final version of your work, and ```push``` your code to your GitHub repository.\n",
    "\n",
    "Submit the URL of your GitHub Repository as your assignment submission on Canvas.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
